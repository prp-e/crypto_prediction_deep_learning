{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "serial-backing",
   "metadata": {},
   "source": [
    "# Crypto price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-setup",
   "metadata": {},
   "source": [
    "In this project, we're going to simply find out how we can do a simple prediction on cryptocurrency prices. This piece of code is heavily inspired by [this video](https://www.youtube.com/watch?v=GFSiL6zEZF0) and it's not a serious project. It's more like some sort of fun project you'd do in a weekend, or a project that shows your abilities in converting your ideas to ML/DL projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-looking",
   "metadata": {},
   "source": [
    "## 0. Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dutch-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pandas_datareader as web\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-pendant",
   "metadata": {},
   "source": [
    "After importing our very essential dependencies like `numpy` or `matplotlib` it is time to just go ahead and decide about what we're going to do with our project. In this part, we decide which currency is our goal. For this particular project, I used Bitcoin. You can use another one like Ethereum, Ripple or Doge. Also, you can change `against_currency` to what you need more that US Dollars. For example you can put it to `CAD` for Canadian Dollar or `EUR` for Euro. It's completely up to you to decide about these currencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "educated-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_currency = \"BTC\"\n",
    "against_currency = \"USD\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-diagnosis",
   "metadata": {},
   "source": [
    "We also need a _time frame_ for our project. This is some sort of daily time frame we've used here and we're monitoring the price of _BTC_ since 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "partial-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime(2018, 1, 1)\n",
    "end_date = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-organization",
   "metadata": {},
   "source": [
    "This part is also for gathering data from _Yahoo Finance API_. For more information about API's, I suggest taking a look at `pandas_datareader` documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "juvenile-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = web.DataReader(f'{crypto_currency}-{against_currency}', 'yahoo', start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intelligent-nicholas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>14112.200195</td>\n",
       "      <td>13154.700195</td>\n",
       "      <td>14112.200195</td>\n",
       "      <td>13657.200195</td>\n",
       "      <td>1.029120e+10</td>\n",
       "      <td>13657.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>15444.599609</td>\n",
       "      <td>13163.599609</td>\n",
       "      <td>13625.000000</td>\n",
       "      <td>14982.099609</td>\n",
       "      <td>1.684660e+10</td>\n",
       "      <td>14982.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>15572.799805</td>\n",
       "      <td>14844.500000</td>\n",
       "      <td>14978.200195</td>\n",
       "      <td>15201.000000</td>\n",
       "      <td>1.687190e+10</td>\n",
       "      <td>15201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>15739.700195</td>\n",
       "      <td>14522.200195</td>\n",
       "      <td>15270.700195</td>\n",
       "      <td>15599.200195</td>\n",
       "      <td>2.178320e+10</td>\n",
       "      <td>15599.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>17705.199219</td>\n",
       "      <td>15202.799805</td>\n",
       "      <td>15477.200195</td>\n",
       "      <td>17429.500000</td>\n",
       "      <td>2.384090e+10</td>\n",
       "      <td>17429.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06</th>\n",
       "      <td>17712.400391</td>\n",
       "      <td>16764.599609</td>\n",
       "      <td>17462.099609</td>\n",
       "      <td>17527.000000</td>\n",
       "      <td>1.831460e+10</td>\n",
       "      <td>17527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-07</th>\n",
       "      <td>17579.599609</td>\n",
       "      <td>16087.700195</td>\n",
       "      <td>17527.300781</td>\n",
       "      <td>16477.599609</td>\n",
       "      <td>1.586600e+10</td>\n",
       "      <td>16477.599609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>16537.900391</td>\n",
       "      <td>14208.200195</td>\n",
       "      <td>16476.199219</td>\n",
       "      <td>15170.099609</td>\n",
       "      <td>1.841390e+10</td>\n",
       "      <td>15170.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>15497.500000</td>\n",
       "      <td>14424.000000</td>\n",
       "      <td>15123.700195</td>\n",
       "      <td>14595.400391</td>\n",
       "      <td>1.666000e+10</td>\n",
       "      <td>14595.400391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>14973.299805</td>\n",
       "      <td>13691.200195</td>\n",
       "      <td>14588.500000</td>\n",
       "      <td>14973.299805</td>\n",
       "      <td>1.850080e+10</td>\n",
       "      <td>14973.299805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    High           Low          Open         Close  \\\n",
       "Date                                                                 \n",
       "2018-01-01  14112.200195  13154.700195  14112.200195  13657.200195   \n",
       "2018-01-02  15444.599609  13163.599609  13625.000000  14982.099609   \n",
       "2018-01-03  15572.799805  14844.500000  14978.200195  15201.000000   \n",
       "2018-01-04  15739.700195  14522.200195  15270.700195  15599.200195   \n",
       "2018-01-05  17705.199219  15202.799805  15477.200195  17429.500000   \n",
       "2018-01-06  17712.400391  16764.599609  17462.099609  17527.000000   \n",
       "2018-01-07  17579.599609  16087.700195  17527.300781  16477.599609   \n",
       "2018-01-08  16537.900391  14208.200195  16476.199219  15170.099609   \n",
       "2018-01-09  15497.500000  14424.000000  15123.700195  14595.400391   \n",
       "2018-01-10  14973.299805  13691.200195  14588.500000  14973.299805   \n",
       "\n",
       "                  Volume     Adj Close  \n",
       "Date                                    \n",
       "2018-01-01  1.029120e+10  13657.200195  \n",
       "2018-01-02  1.684660e+10  14982.099609  \n",
       "2018-01-03  1.687190e+10  15201.000000  \n",
       "2018-01-04  2.178320e+10  15599.200195  \n",
       "2018-01-05  2.384090e+10  17429.500000  \n",
       "2018-01-06  1.831460e+10  17527.000000  \n",
       "2018-01-07  1.586600e+10  16477.599609  \n",
       "2018-01-08  1.841390e+10  15170.099609  \n",
       "2018-01-09  1.666000e+10  14595.400391  \n",
       "2018-01-10  1.850080e+10  14973.299805  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "medical-wound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-03</th>\n",
       "      <td>63516.937500</td>\n",
       "      <td>61184.238281</td>\n",
       "      <td>63254.335938</td>\n",
       "      <td>62970.046875</td>\n",
       "      <td>3.612473e+10</td>\n",
       "      <td>62970.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-04</th>\n",
       "      <td>63123.289062</td>\n",
       "      <td>60799.664062</td>\n",
       "      <td>62941.804688</td>\n",
       "      <td>61452.230469</td>\n",
       "      <td>3.261585e+10</td>\n",
       "      <td>61452.230469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-05</th>\n",
       "      <td>62541.468750</td>\n",
       "      <td>60844.609375</td>\n",
       "      <td>61460.078125</td>\n",
       "      <td>61125.675781</td>\n",
       "      <td>3.060510e+10</td>\n",
       "      <td>61125.675781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-06</th>\n",
       "      <td>61590.683594</td>\n",
       "      <td>60163.781250</td>\n",
       "      <td>61068.875000</td>\n",
       "      <td>61527.480469</td>\n",
       "      <td>2.909493e+10</td>\n",
       "      <td>61527.480469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-07</th>\n",
       "      <td>63326.988281</td>\n",
       "      <td>61432.488281</td>\n",
       "      <td>61554.921875</td>\n",
       "      <td>63326.988281</td>\n",
       "      <td>2.472675e+10</td>\n",
       "      <td>63326.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-08</th>\n",
       "      <td>67673.742188</td>\n",
       "      <td>63344.066406</td>\n",
       "      <td>63344.066406</td>\n",
       "      <td>67566.828125</td>\n",
       "      <td>4.112561e+10</td>\n",
       "      <td>67566.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09</th>\n",
       "      <td>68530.335938</td>\n",
       "      <td>66382.062500</td>\n",
       "      <td>67549.734375</td>\n",
       "      <td>66971.828125</td>\n",
       "      <td>4.235799e+10</td>\n",
       "      <td>66971.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-10</th>\n",
       "      <td>68789.625000</td>\n",
       "      <td>63208.113281</td>\n",
       "      <td>66953.335938</td>\n",
       "      <td>64995.230469</td>\n",
       "      <td>4.873083e+10</td>\n",
       "      <td>64995.230469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-11</th>\n",
       "      <td>65579.015625</td>\n",
       "      <td>64180.488281</td>\n",
       "      <td>64978.890625</td>\n",
       "      <td>64949.960938</td>\n",
       "      <td>3.588063e+10</td>\n",
       "      <td>64949.960938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-12</th>\n",
       "      <td>65420.230469</td>\n",
       "      <td>64312.015625</td>\n",
       "      <td>64858.250000</td>\n",
       "      <td>64986.277344</td>\n",
       "      <td>3.524639e+10</td>\n",
       "      <td>64986.277344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    High           Low          Open         Close  \\\n",
       "Date                                                                 \n",
       "2021-11-03  63516.937500  61184.238281  63254.335938  62970.046875   \n",
       "2021-11-04  63123.289062  60799.664062  62941.804688  61452.230469   \n",
       "2021-11-05  62541.468750  60844.609375  61460.078125  61125.675781   \n",
       "2021-11-06  61590.683594  60163.781250  61068.875000  61527.480469   \n",
       "2021-11-07  63326.988281  61432.488281  61554.921875  63326.988281   \n",
       "2021-11-08  67673.742188  63344.066406  63344.066406  67566.828125   \n",
       "2021-11-09  68530.335938  66382.062500  67549.734375  66971.828125   \n",
       "2021-11-10  68789.625000  63208.113281  66953.335938  64995.230469   \n",
       "2021-11-11  65579.015625  64180.488281  64978.890625  64949.960938   \n",
       "2021-11-12  65420.230469  64312.015625  64858.250000  64986.277344   \n",
       "\n",
       "                  Volume     Adj Close  \n",
       "Date                                    \n",
       "2021-11-03  3.612473e+10  62970.046875  \n",
       "2021-11-04  3.261585e+10  61452.230469  \n",
       "2021-11-05  3.060510e+10  61125.675781  \n",
       "2021-11-06  2.909493e+10  61527.480469  \n",
       "2021-11-07  2.472675e+10  63326.988281  \n",
       "2021-11-08  4.112561e+10  67566.828125  \n",
       "2021-11-09  4.235799e+10  66971.828125  \n",
       "2021-11-10  4.873083e+10  64995.230469  \n",
       "2021-11-11  3.588063e+10  64949.960938  \n",
       "2021-11-12  3.524639e+10  64986.277344  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-bridal",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "improving-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-million",
   "metadata": {},
   "source": [
    "Now we need to scale our data. As we're going to use a Neural Network, it's better to scale our data to something between 0 and 1, or -1 to 1. It all depends on what our input data is. In this case, 0 to 1 is preferred, as _price_ is always a positive number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hungarian-gamma",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-massage",
   "metadata": {},
   "source": [
    "What we've chosen here as our goal for prediction is the _Close_ price (you may chose others such as _Open_ or _High_, but _Close_ price is what we consider for making decisions about our future trades or purchases. And I guess it'd be fun to mess around with other parts of the dataset as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ongoing-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scaler.fit_transform(data[\"Close\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-dietary",
   "metadata": {},
   "source": [
    "## 1.1. Making Neural-Network friendly data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-thesis",
   "metadata": {},
   "source": [
    "First, we need to find out our chunk of time that we want to put our predictions based on. In this example, I have choses 30 days. The main reason for this is that I do not really want to rely on this as a serious tool. I just wanted to test some ideas, so 30 days for a time period is far more than enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "environmental-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_days = 30 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-conference",
   "metadata": {},
   "source": [
    "I highly recommend using `train_test_split` to most of my friends when they do ML/DL projects. But in this particular case, as we wanted a specific chunk of our data, I do it this way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "extraordinary-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "\n",
    "for x in range(prediction_days, len(scaled_data)):\n",
    "    x_train.append(scaled_data[x-prediction_days:x, 0])\n",
    "    y_train.append(scaled_data[x, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-irrigation",
   "metadata": {},
   "source": [
    "Remember that the nueral network will accept a _numpy array_ as an input, so we need to convert our input data to numpy arrays before doing anything serious with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "amazing-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-sunglasses",
   "metadata": {},
   "source": [
    "And finally, we're going to do some reshaping to our `x_train` part of the data. `x` is usually called _independent variable_ and if you pay attention closely, you see that it includes our time chunks. Neural networks need some 3-dimensional type of input for `x` axis. So this is why we add this simple dimension to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "matched-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-gamma",
   "metadata": {},
   "source": [
    "## 2. Welcome to the circus!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-operations",
   "metadata": {},
   "source": [
    "Now we're going to do the DL magic. For this particular project, LSTM is preferred because it is based on a short-term type of data. This is why we've chosen this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "emerging-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-feature",
   "metadata": {},
   "source": [
    "Now we create our model like this. We add to many `Dropout` layers to make sure our model doesn't do overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fitting-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-accordance",
   "metadata": {},
   "source": [
    "And here, we just _compile_ a model. a compiled model, has nothing to do yet. We just create some sort of _brain_ which has nothing in it. Like a new-born (this is a bad example by the way. Because new-borns have a lot in their genetic code. This is why babies can make noises or cry when they need food or some other type of attention). \n",
    "\n",
    "In this new brain, we have to _fit_ the data. Which we exactly have done in the very next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "immune-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-fisher",
   "metadata": {},
   "source": [
    "## 2.1. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "optional-ireland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "44/44 [==============================] - 4s 21ms/step - loss: 0.0115\n",
      "Epoch 2/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0021\n",
      "Epoch 3/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0023\n",
      "Epoch 4/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0021\n",
      "Epoch 5/25\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.0016\n",
      "Epoch 6/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0017\n",
      "Epoch 7/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0017\n",
      "Epoch 8/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0024\n",
      "Epoch 9/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0014\n",
      "Epoch 10/25\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.0013\n",
      "Epoch 11/25\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.0013\n",
      "Epoch 12/25\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 0.0012\n",
      "Epoch 13/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0013\n",
      "Epoch 14/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0015\n",
      "Epoch 15/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0012\n",
      "Epoch 16/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.4226e-04\n",
      "Epoch 17/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0010\n",
      "Epoch 18/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.4636e-04\n",
      "Epoch 19/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.9473e-04\n",
      "Epoch 20/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0011\n",
      "Epoch 21/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0011\n",
      "Epoch 22/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.1845e-04\n",
      "Epoch 23/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.6298e-04\n",
      "Epoch 24/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.4391e-04\n",
      "Epoch 25/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.3062e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff785f37820>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-quantity",
   "metadata": {},
   "source": [
    "## 3. Preparing for the tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-stewart",
   "metadata": {},
   "source": [
    "In this section, we're just going to repeat some parts again. Reason? Because we need som _test data_. So this is why we have this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "enormous-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start_date = dt.datetime(2020, 1, 1)\n",
    "test_end_date = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-neighbor",
   "metadata": {},
   "source": [
    "We again get data from _Yahoo Finance API_ and store it in a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "geological-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data = web.DataReader(f'{crypto_currency}-{against_currency}', 'yahoo', test_start_date, test_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "renewable-truck",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>7254.330566</td>\n",
       "      <td>7174.944336</td>\n",
       "      <td>7194.892090</td>\n",
       "      <td>7200.174316</td>\n",
       "      <td>1.856566e+10</td>\n",
       "      <td>7200.174316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>7212.155273</td>\n",
       "      <td>6935.270020</td>\n",
       "      <td>7202.551270</td>\n",
       "      <td>6985.470215</td>\n",
       "      <td>2.080208e+10</td>\n",
       "      <td>6985.470215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>7413.715332</td>\n",
       "      <td>6914.996094</td>\n",
       "      <td>6984.428711</td>\n",
       "      <td>7344.884277</td>\n",
       "      <td>2.811148e+10</td>\n",
       "      <td>7344.884277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   High          Low         Open        Close        Volume  \\\n",
       "Date                                                                           \n",
       "2020-01-01  7254.330566  7174.944336  7194.892090  7200.174316  1.856566e+10   \n",
       "2020-01-02  7212.155273  6935.270020  7202.551270  6985.470215  2.080208e+10   \n",
       "2020-01-03  7413.715332  6914.996094  6984.428711  7344.884277  2.811148e+10   \n",
       "\n",
       "              Adj Close  \n",
       "Date                     \n",
       "2020-01-01  7200.174316  \n",
       "2020-01-02  6985.470215  \n",
       "2020-01-03  7344.884277  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-compatibility",
   "metadata": {},
   "source": [
    "This is the most confusing part of the project. First, we create a huge list of values from our test data. Which are actual prices of Bitcoin (or other currency of your choice. Remember you also can do this to non-crypto currencies as well) and we need them to see how accurate our model was. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "second-pathology",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_prices = test_data['Close'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-rochester",
   "metadata": {},
   "source": [
    "And here, we just add the whole test data to our bigger dataset. The reason here is having no trouble in testing the model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "restricted-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.concat((data['Close'], test_data['Close']), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-sherman",
   "metadata": {},
   "source": [
    "## 4. Making desired inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-divorce",
   "metadata": {},
   "source": [
    "For models, we need different inputs, right? here we just filter out our inputs to something we need. We exactly need the past 30 days of data and this is how we do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "incomplete-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = total_data[len(total_data) - len(test_data) - prediction_days:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-insertion",
   "metadata": {},
   "source": [
    "Then, we need to reshape our data in case we need to scale them. It is pretty much similar to what we've done with our very first input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "anonymous-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = model_inputs.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-mount",
   "metadata": {},
   "source": [
    "And here, we just scale down our data because our model understand it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "every-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = scaler.fit_transform(model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-plaintiff",
   "metadata": {},
   "source": [
    "## 4.1. Making the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "simplified-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "\n",
    "for x in range(prediction_days, len(model_inputs)):\n",
    "    x_test.append(model_inputs[x-prediction_days:x , 0])\n",
    "    \n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-buying",
   "metadata": {},
   "source": [
    "We just fill our array as before. Nothing has changed. And we do reshaping because we have done it on our training data (and reasons for that are up there). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "northern-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-instruction",
   "metadata": {},
   "source": [
    "## 5. Predictions, finally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "reserved-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_price = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "documentary-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_price = scaler.inverse_transform(predicted_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-aruba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
