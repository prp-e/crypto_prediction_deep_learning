{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "centered-hands",
   "metadata": {},
   "source": [
    "# Crypto price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-carry",
   "metadata": {},
   "source": [
    "In this project, we're going to simply find out how we can do a simple prediction on cryptocurrency prices. This piece of code is heavily inspired by [this video](https://www.youtube.com/watch?v=GFSiL6zEZF0) and it's not a serious project. It's more like some sort of fun project you'd do in a weekend, or a project that shows your abilities in converting your ideas to ML/DL projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-atlas",
   "metadata": {},
   "source": [
    "## 0. Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unlimited-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import pandas_datareader as web\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-finance",
   "metadata": {},
   "source": [
    "After importing our very essential dependencies like `numpy` or `matplotlib` it is time to just go ahead and decide about what we're going to do with our project. In this part, we decide which currency is our goal. For this particular project, I used Bitcoin. You can use another one like Ethereum, Ripple or Doge. Also, you can change `against_currency` to what you need more that US Dollars. For example you can put it to `CAD` for Canadian Dollar or `EUR` for Euro. It's completely up to you to decide about these currencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "black-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_currency = \"BTC\"\n",
    "against_currency = \"USD\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-building",
   "metadata": {},
   "source": [
    "We also need a _time frame_ for our project. This is some sort of daily time frame we've used here and we're monitoring the price of _BTC_ since 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "royal-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime(2018, 1, 1)\n",
    "end_date = dt.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-harvest",
   "metadata": {},
   "source": [
    "This part is also for gathering data from _Yahoo Finance API_. For more information about API's, I suggest taking a look at `pandas_datareader` documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "african-miller",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = web.DataReader(f'{crypto_currency}-{against_currency}', 'yahoo', start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stuck-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>14112.200195</td>\n",
       "      <td>13154.700195</td>\n",
       "      <td>14112.200195</td>\n",
       "      <td>13657.200195</td>\n",
       "      <td>1.029120e+10</td>\n",
       "      <td>13657.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-02</th>\n",
       "      <td>15444.599609</td>\n",
       "      <td>13163.599609</td>\n",
       "      <td>13625.000000</td>\n",
       "      <td>14982.099609</td>\n",
       "      <td>1.684660e+10</td>\n",
       "      <td>14982.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>15572.799805</td>\n",
       "      <td>14844.500000</td>\n",
       "      <td>14978.200195</td>\n",
       "      <td>15201.000000</td>\n",
       "      <td>1.687190e+10</td>\n",
       "      <td>15201.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>15739.700195</td>\n",
       "      <td>14522.200195</td>\n",
       "      <td>15270.700195</td>\n",
       "      <td>15599.200195</td>\n",
       "      <td>2.178320e+10</td>\n",
       "      <td>15599.200195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>17705.199219</td>\n",
       "      <td>15202.799805</td>\n",
       "      <td>15477.200195</td>\n",
       "      <td>17429.500000</td>\n",
       "      <td>2.384090e+10</td>\n",
       "      <td>17429.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-06</th>\n",
       "      <td>17712.400391</td>\n",
       "      <td>16764.599609</td>\n",
       "      <td>17462.099609</td>\n",
       "      <td>17527.000000</td>\n",
       "      <td>1.831460e+10</td>\n",
       "      <td>17527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-07</th>\n",
       "      <td>17579.599609</td>\n",
       "      <td>16087.700195</td>\n",
       "      <td>17527.300781</td>\n",
       "      <td>16477.599609</td>\n",
       "      <td>1.586600e+10</td>\n",
       "      <td>16477.599609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>16537.900391</td>\n",
       "      <td>14208.200195</td>\n",
       "      <td>16476.199219</td>\n",
       "      <td>15170.099609</td>\n",
       "      <td>1.841390e+10</td>\n",
       "      <td>15170.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>15497.500000</td>\n",
       "      <td>14424.000000</td>\n",
       "      <td>15123.700195</td>\n",
       "      <td>14595.400391</td>\n",
       "      <td>1.666000e+10</td>\n",
       "      <td>14595.400391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>14973.299805</td>\n",
       "      <td>13691.200195</td>\n",
       "      <td>14588.500000</td>\n",
       "      <td>14973.299805</td>\n",
       "      <td>1.850080e+10</td>\n",
       "      <td>14973.299805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    High           Low          Open         Close  \\\n",
       "Date                                                                 \n",
       "2018-01-01  14112.200195  13154.700195  14112.200195  13657.200195   \n",
       "2018-01-02  15444.599609  13163.599609  13625.000000  14982.099609   \n",
       "2018-01-03  15572.799805  14844.500000  14978.200195  15201.000000   \n",
       "2018-01-04  15739.700195  14522.200195  15270.700195  15599.200195   \n",
       "2018-01-05  17705.199219  15202.799805  15477.200195  17429.500000   \n",
       "2018-01-06  17712.400391  16764.599609  17462.099609  17527.000000   \n",
       "2018-01-07  17579.599609  16087.700195  17527.300781  16477.599609   \n",
       "2018-01-08  16537.900391  14208.200195  16476.199219  15170.099609   \n",
       "2018-01-09  15497.500000  14424.000000  15123.700195  14595.400391   \n",
       "2018-01-10  14973.299805  13691.200195  14588.500000  14973.299805   \n",
       "\n",
       "                  Volume     Adj Close  \n",
       "Date                                    \n",
       "2018-01-01  1.029120e+10  13657.200195  \n",
       "2018-01-02  1.684660e+10  14982.099609  \n",
       "2018-01-03  1.687190e+10  15201.000000  \n",
       "2018-01-04  2.178320e+10  15599.200195  \n",
       "2018-01-05  2.384090e+10  17429.500000  \n",
       "2018-01-06  1.831460e+10  17527.000000  \n",
       "2018-01-07  1.586600e+10  16477.599609  \n",
       "2018-01-08  1.841390e+10  15170.099609  \n",
       "2018-01-09  1.666000e+10  14595.400391  \n",
       "2018-01-10  1.850080e+10  14973.299805  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mighty-roller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-03</th>\n",
       "      <td>63516.937500</td>\n",
       "      <td>61184.238281</td>\n",
       "      <td>63254.335938</td>\n",
       "      <td>62970.046875</td>\n",
       "      <td>3.612473e+10</td>\n",
       "      <td>62970.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-04</th>\n",
       "      <td>63123.289062</td>\n",
       "      <td>60799.664062</td>\n",
       "      <td>62941.804688</td>\n",
       "      <td>61452.230469</td>\n",
       "      <td>3.261585e+10</td>\n",
       "      <td>61452.230469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-05</th>\n",
       "      <td>62541.468750</td>\n",
       "      <td>60844.609375</td>\n",
       "      <td>61460.078125</td>\n",
       "      <td>61125.675781</td>\n",
       "      <td>3.060510e+10</td>\n",
       "      <td>61125.675781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-06</th>\n",
       "      <td>61590.683594</td>\n",
       "      <td>60163.781250</td>\n",
       "      <td>61068.875000</td>\n",
       "      <td>61527.480469</td>\n",
       "      <td>2.909493e+10</td>\n",
       "      <td>61527.480469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-07</th>\n",
       "      <td>63326.988281</td>\n",
       "      <td>61432.488281</td>\n",
       "      <td>61554.921875</td>\n",
       "      <td>63326.988281</td>\n",
       "      <td>2.472675e+10</td>\n",
       "      <td>63326.988281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-08</th>\n",
       "      <td>67673.742188</td>\n",
       "      <td>63344.066406</td>\n",
       "      <td>63344.066406</td>\n",
       "      <td>67566.828125</td>\n",
       "      <td>4.112561e+10</td>\n",
       "      <td>67566.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09</th>\n",
       "      <td>68530.335938</td>\n",
       "      <td>66382.062500</td>\n",
       "      <td>67549.734375</td>\n",
       "      <td>66971.828125</td>\n",
       "      <td>4.235799e+10</td>\n",
       "      <td>66971.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-10</th>\n",
       "      <td>68789.625000</td>\n",
       "      <td>63208.113281</td>\n",
       "      <td>66953.335938</td>\n",
       "      <td>64995.230469</td>\n",
       "      <td>4.873083e+10</td>\n",
       "      <td>64995.230469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-11</th>\n",
       "      <td>65579.015625</td>\n",
       "      <td>64180.488281</td>\n",
       "      <td>64978.890625</td>\n",
       "      <td>64949.960938</td>\n",
       "      <td>3.588063e+10</td>\n",
       "      <td>64949.960938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-12</th>\n",
       "      <td>65420.230469</td>\n",
       "      <td>64312.015625</td>\n",
       "      <td>64858.250000</td>\n",
       "      <td>64986.277344</td>\n",
       "      <td>3.524639e+10</td>\n",
       "      <td>64986.277344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    High           Low          Open         Close  \\\n",
       "Date                                                                 \n",
       "2021-11-03  63516.937500  61184.238281  63254.335938  62970.046875   \n",
       "2021-11-04  63123.289062  60799.664062  62941.804688  61452.230469   \n",
       "2021-11-05  62541.468750  60844.609375  61460.078125  61125.675781   \n",
       "2021-11-06  61590.683594  60163.781250  61068.875000  61527.480469   \n",
       "2021-11-07  63326.988281  61432.488281  61554.921875  63326.988281   \n",
       "2021-11-08  67673.742188  63344.066406  63344.066406  67566.828125   \n",
       "2021-11-09  68530.335938  66382.062500  67549.734375  66971.828125   \n",
       "2021-11-10  68789.625000  63208.113281  66953.335938  64995.230469   \n",
       "2021-11-11  65579.015625  64180.488281  64978.890625  64949.960938   \n",
       "2021-11-12  65420.230469  64312.015625  64858.250000  64986.277344   \n",
       "\n",
       "                  Volume     Adj Close  \n",
       "Date                                    \n",
       "2021-11-03  3.612473e+10  62970.046875  \n",
       "2021-11-04  3.261585e+10  61452.230469  \n",
       "2021-11-05  3.060510e+10  61125.675781  \n",
       "2021-11-06  2.909493e+10  61527.480469  \n",
       "2021-11-07  2.472675e+10  63326.988281  \n",
       "2021-11-08  4.112561e+10  67566.828125  \n",
       "2021-11-09  4.235799e+10  66971.828125  \n",
       "2021-11-10  4.873083e+10  64995.230469  \n",
       "2021-11-11  3.588063e+10  64949.960938  \n",
       "2021-11-12  3.524639e+10  64986.277344  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-cancer",
   "metadata": {},
   "source": [
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "virtual-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-stylus",
   "metadata": {},
   "source": [
    "Now we need to scale our data. As we're going to use a Neural Network, it's better to scale our data to something between 0 and 1, or -1 to 1. It all depends on what our input data is. In this case, 0 to 1 is preferred, as _price_ is always a positive number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "temporal-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-diana",
   "metadata": {},
   "source": [
    "What we've chosen here as our goal for prediction is the _Close_ price (you may chose others such as _Open_ or _High_, but _Close_ price is what we consider for making decisions about our future trades or purchases. And I guess it'd be fun to mess around with other parts of the dataset as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "returning-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scaler.fit_transform(data[\"Close\"].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-specific",
   "metadata": {},
   "source": [
    "## 1.1. Making Neural-Network friendly data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-biography",
   "metadata": {},
   "source": [
    "First, we need to find out our chunk of time that we want to put our predictions based on. In this example, I have choses 30 days. The main reason for this is that I do not really want to rely on this as a serious tool. I just wanted to test some ideas, so 30 days for a time period is far more than enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "diagnostic-terror",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_days = 30 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-furniture",
   "metadata": {},
   "source": [
    "I highly recommend using `train_test_split` to most of my friends when they do ML/DL projects. But in this particular case, as we wanted a specific chunk of our data, I do it this way: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "innovative-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "\n",
    "for x in range(prediction_days, len(scaled_data)):\n",
    "    x_train.append(scaled_data[x-prediction_days:x, 0])\n",
    "    y_train.append(scaled_data[x, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-anime",
   "metadata": {},
   "source": [
    "Remember that the nueral network will accept a _numpy array_ as an input, so we need to convert our input data to numpy arrays before doing anything serious with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "antique-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-caution",
   "metadata": {},
   "source": [
    "And finally, we're going to do some reshaping to our `x_train` part of the data. `x` is usually called _independent variable_ and if you pay attention closely, you see that it includes our time chunks. Neural networks need some 3-dimensional type of input for `x` axis. So this is why we add this simple dimension to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "happy-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-fusion",
   "metadata": {},
   "source": [
    "## 2. Welcome to the circus!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-apollo",
   "metadata": {},
   "source": [
    "Now we're going to do the DL magic. For this particular project, LSTM is preferred because it is based on a short-term type of data. This is why we've chosen this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjusted-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-sense",
   "metadata": {},
   "source": [
    "Now we create our model like this. We add to many `Dropout` layers to make sure our model doesn't do overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "personal-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-oxide",
   "metadata": {},
   "source": [
    "And here, we just _compile_ a model. a compiled model, has nothing to do yet. We just create some sort of _brain_ which has nothing in it. Like a new-born (this is a bad exa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "framed-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "overall-terminology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "44/44 [==============================] - 4s 21ms/step - loss: 0.0115\n",
      "Epoch 2/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0021\n",
      "Epoch 3/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0023\n",
      "Epoch 4/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0021\n",
      "Epoch 5/25\n",
      "44/44 [==============================] - 1s 23ms/step - loss: 0.0016\n",
      "Epoch 6/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0017\n",
      "Epoch 7/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0017\n",
      "Epoch 8/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0024\n",
      "Epoch 9/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0014\n",
      "Epoch 10/25\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.0013\n",
      "Epoch 11/25\n",
      "44/44 [==============================] - 1s 21ms/step - loss: 0.0013\n",
      "Epoch 12/25\n",
      "44/44 [==============================] - 1s 22ms/step - loss: 0.0012\n",
      "Epoch 13/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0013\n",
      "Epoch 14/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0015\n",
      "Epoch 15/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0012\n",
      "Epoch 16/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.4226e-04\n",
      "Epoch 17/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0010\n",
      "Epoch 18/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.4636e-04\n",
      "Epoch 19/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.9473e-04\n",
      "Epoch 20/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0011\n",
      "Epoch 21/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 0.0011\n",
      "Epoch 22/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.1845e-04\n",
      "Epoch 23/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.6298e-04\n",
      "Epoch 24/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.4391e-04\n",
      "Epoch 25/25\n",
      "44/44 [==============================] - 1s 20ms/step - loss: 9.3062e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff785f37820>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-ethnic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
